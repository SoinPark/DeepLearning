{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "8c1eae21719a0790335dcb83aad72b63b602cfe5cdb2bda0f60bc11d4f154e4b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 원, 삼각형, 사각형 구분하기"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "seed = 2021\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "source": [
    "## 데이터셋 생성하기"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 45 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1/225.)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'handwriting_shape/train',\n",
    "    target_size=(24,24),\n",
    "    batch_size=3,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 15 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1/225.)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'handwriting_shape/test',\n",
    "    target_size=(24,24),\n",
    "    batch_size=3,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "train_generator.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'circle\\\\circle001.png'"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "train_generator.filenames[0]"
   ]
  },
  {
   "source": [
    "## 모델 정의/설정/학습"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 22, 22, 32)        896       \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 20, 20, 64)        18496     \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 10, 10, 64)        0         \n_________________________________________________________________\nflatten (Flatten)            (None, 6400)              0         \n_________________________________________________________________\ndense (Dense)                (None, 128)               819328    \n_________________________________________________________________\ndense_1 (Dense)              (None, 3)                 387       \n=================================================================\nTotal params: 839,107\nTrainable params: 839,107\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), input_shape=(24,24,3), activation='relu'),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "source": [
    "## 모델 학습\n",
    "- 첫번째 인자: 훈련데이터셋을 제공한 제네레이터를 지정. 본 예제에서는 앞서 생성한 train_generator로 지정\n",
    "- steps_per_epoch : 한 epoch에 사용한 스텝 수를 지정. 총 45개의 훈련 샘플이 있고 배치사이즈가 3이므로 15 스텝으로 지정.\n",
    "- epochs : 전체 훈련 데이터셋에 대해 학습 반복 횟수를 지정. 50번을 반복적으로 학습.\n",
    "- validation_data : 검증데이터셋을 제공할 제네레이터를 지정. 본 예제에서는 앞서 생성한 test_generator으로 지정.\n",
    "- validation_steps : 한 epoch 종료 시 마다 검증할 때 사용되는 검증 스텝 수를 지정. 총 15개의 검증 샘플이 있고 배치사이즈가 3이므로 5 스텝으로 지정."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=============================] - 0s 9ms/step - loss: 6.0134e-07 - accuracy: 1.0000 - val_loss: 0.0317 - val_accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 5.7485e-07 - accuracy: 1.0000 - val_loss: 0.0327 - val_accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 5.5896e-07 - accuracy: 1.0000 - val_loss: 0.0322 - val_accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 5.3247e-07 - accuracy: 1.0000 - val_loss: 0.0324 - val_accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 5.2452e-07 - accuracy: 1.0000 - val_loss: 0.0322 - val_accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 5.1392e-07 - accuracy: 1.0000 - val_loss: 0.0341 - val_accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 4.9008e-07 - accuracy: 1.0000 - val_loss: 0.0335 - val_accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 4.8213e-07 - accuracy: 1.0000 - val_loss: 0.0327 - val_accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 4.7154e-07 - accuracy: 1.0000 - val_loss: 0.0346 - val_accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 4.5035e-07 - accuracy: 1.0000 - val_loss: 0.0342 - val_accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 4.2915e-07 - accuracy: 1.0000 - val_loss: 0.0346 - val_accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 4.2650e-07 - accuracy: 1.0000 - val_loss: 0.0339 - val_accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 4.1591e-07 - accuracy: 1.0000 - val_loss: 0.0340 - val_accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 4.0266e-07 - accuracy: 1.0000 - val_loss: 0.0349 - val_accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 3.9207e-07 - accuracy: 1.0000 - val_loss: 0.0355 - val_accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 3.7882e-07 - accuracy: 1.0000 - val_loss: 0.0355 - val_accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 3.7352e-07 - accuracy: 1.0000 - val_loss: 0.0350 - val_accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 3.6293e-07 - accuracy: 1.0000 - val_loss: 0.0358 - val_accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 3.4703e-07 - accuracy: 1.0000 - val_loss: 0.0355 - val_accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 3.3643e-07 - accuracy: 1.0000 - val_loss: 0.0360 - val_accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 3.3114e-07 - accuracy: 1.0000 - val_loss: 0.0367 - val_accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 3.2054e-07 - accuracy: 1.0000 - val_loss: 0.0366 - val_accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 3.1524e-07 - accuracy: 1.0000 - val_loss: 0.0368 - val_accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 3.1524e-07 - accuracy: 1.0000 - val_loss: 0.0365 - val_accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 3.0465e-07 - accuracy: 1.0000 - val_loss: 0.0371 - val_accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 2.9405e-07 - accuracy: 1.0000 - val_loss: 0.0366 - val_accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 2.8080e-07 - accuracy: 1.0000 - val_loss: 0.0377 - val_accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 2.7551e-07 - accuracy: 1.0000 - val_loss: 0.0376 - val_accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 2.7815e-07 - accuracy: 1.0000 - val_loss: 0.0366 - val_accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 2.6226e-07 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 2.6491e-07 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 2.5961e-07 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 2.4901e-07 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 2.4372e-07 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 2.3047e-07 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 2.2782e-07 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 2.2252e-07 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 2.1987e-07 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 2.1723e-07 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 2.0928e-07 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 2.0663e-07 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 2.0133e-07 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.9338e-07 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.8014e-07 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 1.7749e-07 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 1.7484e-07 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.7484e-07 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.7219e-07 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.7219e-07 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.7219e-07 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.6689e-07 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 1.6424e-07 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.5630e-07 - accuracy: 1.0000 - val_loss: 0.0434 - val_accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.5365e-07 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.5100e-07 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.4570e-07 - accuracy: 1.0000 - val_loss: 0.0434 - val_accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 1.4040e-07 - accuracy: 1.0000 - val_loss: 0.0444 - val_accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 1.3775e-07 - accuracy: 1.0000 - val_loss: 0.0443 - val_accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.3510e-07 - accuracy: 1.0000 - val_loss: 0.0447 - val_accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 1.3510e-07 - accuracy: 1.0000 - val_loss: 0.0451 - val_accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.3245e-07 - accuracy: 1.0000 - val_loss: 0.0447 - val_accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.2716e-07 - accuracy: 1.0000 - val_loss: 0.0451 - val_accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 1.2716e-07 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 1.3245e-07 - accuracy: 1.0000 - val_loss: 0.0468 - val_accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.2716e-07 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.2716e-07 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.2186e-07 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.1656e-07 - accuracy: 1.0000 - val_loss: 0.0478 - val_accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 1.1656e-07 - accuracy: 1.0000 - val_loss: 0.0474 - val_accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 1.1126e-07 - accuracy: 1.0000 - val_loss: 0.0467 - val_accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 1.1126e-07 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 1.0861e-07 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 1.0861e-07 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.0331e-07 - accuracy: 1.0000 - val_loss: 0.0475 - val_accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 1.0067e-07 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 1.0067e-07 - accuracy: 1.0000 - val_loss: 0.0477 - val_accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 1.0067e-07 - accuracy: 1.0000 - val_loss: 0.0480 - val_accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 9.8017e-08 - accuracy: 1.0000 - val_loss: 0.0478 - val_accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 9.5367e-08 - accuracy: 1.0000 - val_loss: 0.0478 - val_accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 9.5367e-08 - accuracy: 1.0000 - val_loss: 0.0478 - val_accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 9.0069e-08 - accuracy: 1.0000 - val_loss: 0.0485 - val_accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 9.0069e-08 - accuracy: 1.0000 - val_loss: 0.0489 - val_accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 9.0069e-08 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 9.0069e-08 - accuracy: 1.0000 - val_loss: 0.0486 - val_accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 8.7420e-08 - accuracy: 1.0000 - val_loss: 0.0489 - val_accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 8.7420e-08 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 8.4771e-08 - accuracy: 1.0000 - val_loss: 0.0494 - val_accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 8.2122e-08 - accuracy: 1.0000 - val_loss: 0.0492 - val_accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 8.2122e-08 - accuracy: 1.0000 - val_loss: 0.0492 - val_accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 7.6824e-08 - accuracy: 1.0000 - val_loss: 0.0491 - val_accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 7.6824e-08 - accuracy: 1.0000 - val_loss: 0.0495 - val_accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 7.6824e-08 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 7.4175e-08 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 7.4175e-08 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 7.4175e-08 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 7.4175e-08 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 7.4175e-08 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 7.4175e-08 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 7.4175e-08 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 7.4175e-08 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 7.4175e-08 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 7.4175e-08 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 7.4175e-08 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 7.1526e-08 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 7.1526e-08 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 7.1526e-08 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 7.1526e-08 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 6.6227e-08 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 6.0929e-08 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 5.8280e-08 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 5.5631e-08 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 5.2982e-08 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 5.2982e-08 - accuracy: 1.0000 - val_loss: 0.0534 - val_accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 5.0333e-08 - accuracy: 1.0000 - val_loss: 0.0535 - val_accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 5.0333e-08 - accuracy: 1.0000 - val_loss: 0.0542 - val_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 5.0333e-08 - accuracy: 1.0000 - val_loss: 0.0549 - val_accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 5.0333e-08 - accuracy: 1.0000 - val_loss: 0.0551 - val_accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 5.0333e-08 - accuracy: 1.0000 - val_loss: 0.0555 - val_accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 5.0333e-08 - accuracy: 1.0000 - val_loss: 0.0553 - val_accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 5.0333e-08 - accuracy: 1.0000 - val_loss: 0.0556 - val_accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 5.0333e-08 - accuracy: 1.0000 - val_loss: 0.0559 - val_accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 5.0333e-08 - accuracy: 1.0000 - val_loss: 0.0563 - val_accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 5.0333e-08 - accuracy: 1.0000 - val_loss: 0.0564 - val_accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 5.0333e-08 - accuracy: 1.0000 - val_loss: 0.0567 - val_accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 4.7684e-08 - accuracy: 1.0000 - val_loss: 0.0574 - val_accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 4.7684e-08 - accuracy: 1.0000 - val_loss: 0.0572 - val_accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 4.7684e-08 - accuracy: 1.0000 - val_loss: 0.0573 - val_accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 4.7684e-08 - accuracy: 1.0000 - val_loss: 0.0578 - val_accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 4.7684e-08 - accuracy: 1.0000 - val_loss: 0.0578 - val_accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 4.7684e-08 - accuracy: 1.0000 - val_loss: 0.0580 - val_accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 4.5035e-08 - accuracy: 1.0000 - val_loss: 0.0579 - val_accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 4.5035e-08 - accuracy: 1.0000 - val_loss: 0.0581 - val_accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 4.5035e-08 - accuracy: 1.0000 - val_loss: 0.0585 - val_accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 4.5035e-08 - accuracy: 1.0000 - val_loss: 0.0589 - val_accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 4.5035e-08 - accuracy: 1.0000 - val_loss: 0.0592 - val_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 4.5035e-08 - accuracy: 1.0000 - val_loss: 0.0593 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19f38e06550>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=15,\n",
    "        epochs=50,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=5\n",
    "        )"
   ]
  },
  {
   "source": [
    "## 모델 평가"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 1.0000\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.05926407873630524, 1.0]"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "model.evaluate(test_generator, steps=5)\n",
    " #model.evaluate_generator이라고 쓰면 warning에 generator 쓰지말라고나옴"
   ]
  }
 ]
}